{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilih menu \" **Runtime** \" lalu \" **Run All** \" => \" **Run Anyway** \"\n",
    "\n",
    "# Untuk menjalankan suatu cell (setelah melakukan perubahan) tekan tombol \"CTRL + Enter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium\n",
    "!pip install pyldavis\n",
    "!wget --backups=1 https://tau-data.id/d/taudata_min.py\n",
    "!wget --backups=1 https://tau-data.id/d/stunt1.pkl\n",
    "!wget --backups=1 https://tau-data.id/d/stunt2.pkl\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import taudata_min as tau, folium, pickle\n",
    "from folium import plugins\n",
    "import pandas as pd, seaborn as sns; sns.set()\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis, pyLDAvis.sklearn; pyLDAvis.enable_notebook()\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fData1 = 'stunt1.pkl'\n",
    "fData2 = 'stunt2.pkl'\n",
    "'2018-10-01', '2019-11-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data for interactive visualizations\n",
    "with open(fData1, 'rb') as f:\n",
    "    places, tweets, Dt, koordinat, txtPlaces, lokasi = pickle.load(f)\n",
    "\n",
    "with open(fData2, 'rb') as f:\n",
    "    webpages, webCategory, df_w, Dw  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Lokasi':lokasi})\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.set(style='darkgrid')\n",
    "sns.countplot(y = 'Lokasi', data = df, order = df['Lokasi'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtPlaces['brebes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 10**-4\n",
    "latID, lonID, count = -0.789275, 113.921, 1\n",
    "lat, lon = [], []\n",
    "for i, r in tqdm(tweets.iterrows()):\n",
    "    if (r.lat!=0 and r.lon!=0) and (abs(r.lat-latID)>tolerance and abs(r.lon-lonID)>tolerance):\n",
    "        lat.append(r.lat)\n",
    "        lon.append(r.lon) \n",
    "count = [1]*len(lat)\n",
    "df = pd.DataFrame({'lat':lat, 'lon':lon, 'count':count})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = tau.generateBaseMap()\n",
    "HeatMap(data=df[['lat', 'lon', 'count']].groupby(['lat', 'lon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'Sentiment':sentiments})\n",
    "c = tweets['sentiment'].value_counts()\n",
    "values = c.values\n",
    "colors = ['green', 'red', 'blue']\n",
    "labels = c.index\n",
    "explode = (0.2, 0, 0)\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.pie(values, colors=colors, labels= values, explode=explode, shadow=True, textprops={'fontsize': 20})\n",
    "plt.title('Sentimen Pengguna twitter 1 Okt 2018 - Nov 2019 tentang isu Stunting di Indonesia\\n\\n')\n",
    "plt.legend(labels,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita dalami lebih jauh Topic Pembicaraan ini\n",
    "k = 4 # Jumlah Topik ... menurut CV yg sudah dilakukan 4 adalah yg optimal. Tapi silahkan eksplore utk jumlah topik lainnya\n",
    "Docs_t = [' '.join(d) for d in Dt]\n",
    "tf_t, tm_t, vec_t = tau.getTopics(Docs_t, n_topics=k, Top_Words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(tf_t, tm_t, vec_t)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisa pada data Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.set(style='darkgrid')\n",
    "sns.countplot(y = 'Website', data = df_w, order = df_w['Website'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita dalami lebih jauh Topic Pembicaraan ini\n",
    "k = 3\n",
    "Docs_w = [' '.join(d) for d in Dw]\n",
    "tf_w, tm_w, vec_w = tau.getTopics(Docs_w, n_topics=k, Top_Words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(tf_w, tm_w, vec_w)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = []\n",
    "for i, r in tweets.iterrows():\n",
    "    Tweets.append([r.username, r.tweet])\n",
    "    \n",
    "G = tau.Graph(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now examine, who are the most \"important\" users in this Graph?\n",
    "\"\"\"\n",
    "silahkan pilih dari beberapa metode ini\n",
    "degree = important karena banyak yang mention atau dimention\n",
    "closeness = important karena jaraknya dengan semua user lain. Informasi akan cepat menyebar melalui orang ini\n",
    "eigen = important karena user tersebut ber-degree tinggi atau degree rendah tapi mempengaruhi orang yg degree tinggi (kuda hitam)\n",
    "betweeness = user-user ini important karena bisa mencegah suatu informasi menyebar lebih jauh\n",
    "\n",
    "N = jumlah important user yang ingin ditampilkan\n",
    "\"\"\"\n",
    "Gt = tau.Centrality(G, N=5, method='degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.drawGraph(Gt, Label = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemisahan Text dan Topic Modelling Berdasarkan Kategori Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webCategory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cats = list(set(webCategory.category))\n",
    "Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silahkan rubah 'cat' menjadi = ['NGO', 'Pemerintah Daerah', 'Pemerintah Pusat', 'Portal']\n",
    "# Lalu jalankan cell ini : \"tombol ctrl+Enter\"\n",
    "cat, k = 'NGO', 3\n",
    "Docs = []\n",
    "for i, r in tqdm(webCategory.iterrows()):\n",
    "    if r.category == cat:\n",
    "        Docs.append(r.content)\n",
    "        \n",
    "tf, tm, vec = tau.getTopics(Docs, n_topics=k, Top_Words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi topic dari cell diatas (tekan tombol ctrl+Enter, lalu tunggu ... biasanya agak lama utk graphics muncul)\n",
    "pyLDAvis.sklearn.prepare(tf, tm, vec)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemisahan, preprocessing, dan penyimpanan Text Tweets berdasarkan Lokus Penelitian dan Sentiment untuk dilakukan Text Analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics dapat dilakukan dengan cara:\n",
    "\n",
    "1. Buka https://voyant-tools.org/\n",
    "2. Upload berbagai file Text, misal Tweet_solok.txt, Web_NGO.txt, dsb ==> file-file ini sudah dikirim melalui email dan WA\n",
    "3. Pilih berbagai visualisasi yang dibutuhkan: WordCloud, WordLinks, Word Tree, dsb"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
