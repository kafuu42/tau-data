{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"images/Cover.jpg\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">Decision Tree, Random Forest, and Naive Bayes Classifier</font></center>\n",
    "\n",
    "<h2 id=\"(C)-Taufik-Sutanto---2019\" style=\"text-align: center;\">(C) Taufik Sutanto - 2019</h2>\n",
    "<h2 id=\"tau-data-Indonesia-~-https://tau-data.id\" style=\"text-align: center;\">tau-data Indonesia ~ <a href=\"https://tau-data.id\" target=\"_blank\"><span style=\"color: #0009ff;\">https://tau-data.id</span></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes and Disclaimer\n",
    "\n",
    "* This notebook is part of the free (open knowledge) eLearning course at: https://tau-data.id/courses/\n",
    "* Some images are taken from several resources, we respect those images ownerships and put a reference/citation from where it is originated. Nevertheless, sometimes we are having trouble to find the origin of the image(s). If you are the owner of the image and would like the image taken-out (or want the citation to be revised) from this open knowledge course resources please contact us here with the details: https://tau-data.id/contact/  \n",
    "* Unless stated otherwise, in general tau-data permit its resources to be copied and-or modified for non-commercial purposes. With condition proper acknowledgement/citation is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Modules\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "!pip install graphviz\n",
    "!pip install dtreeviz\n",
    "import graphviz, pandas as pd, matplotlib.pyplot as plt, numpy as np, seaborn as sns\n",
    "from pandas.plotting import scatter_matrix \n",
    "from sklearn import model_selection, tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from dtreeviz.trees import *\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outline:\n",
    "\n",
    "* Review Kuliah Sebelumnya\n",
    "* Some quick (Python) codes for the previous lectures \n",
    "* Decision Tree, \n",
    "* Random Forest, \n",
    "* Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Review:\n",
    "<img alt=\"\" src=\"images/KDD.jpg\" style=\"width: 650px; height: 376px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule: Rule, Support, Confidence, Lift by Example\n",
    "<img alt=\"\" src=\"images/Rule_Lift_Support_Confidence.png\" style=\"width: 300px ; height: 181px\" />\n",
    "<img alt=\"\" src=\"images/Rule_Lift_Support_Confidence_example.png\" style=\"width: 300px; height: 222px;\" />\n",
    "* http://www.saedsayad.com/association_rules.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "<img alt=\"\" src=\"images/reg_to_log.png\" style=\"width: 650px; height: 328px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kembali ke Teori dulu sebelum melanjutkan aplikasinya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/Sejarah_ML_AI.jpg\" />\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sejarah Metode Konvensional di ML/DS\n",
    "\n",
    "* Bayesian\t\t: 1763 Thomas Bayes, Statisticians\n",
    "* Regresi\t\t: Abad 19 (~18XX), Francis Galton (biologist)\n",
    "* Decision Tree\t: 1959, William Belson, biologist\u000b",
    "\t\t\t  (popular oleh R. Quinlan 80-an ID3 & CART oleh )\n",
    "* Perceptron\t\t: 1962, Frank Rosenblatt, psychologist\n",
    "* SVM\t\t: 1963, Vapnik, Mathematics and Statistics.\n",
    "* Neural network\t: 1974, Werbos (backprop), 1990 Hecht-Nielsen (MLP)(setelah perceptron)\n",
    "* Semi-Supervised\t: 1965 Scruder, tapi popular 2008 Zhu (comp scientist)\n",
    "* Ensemble\t\t: 1979, Dasarathy, \n",
    "* Deep learning\t: in more detail in the next cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularitas DL\n",
    "\n",
    "* Ketika ML (SVM) sedang populer di tahun 2010, beberapa peneliti tetap mendalami NN, diantaranya nama-nama tenar seperti Geoffrey Hinton di the University of Toronto, dan Yann LeCun di New York University.\n",
    "* Deep Learning dengan GPU dimulai di tahun 2011 (Dan Ciresan dari  IDSIA-Swiss)\n",
    "* Namun di 2012 baru terkenal karena permasalahan klasifikasi ImageNet (~1,4 juta image dikategorikan ke 1000 kelas) mampu diselesaikan oleh Hinton. Awalnya akurasinya 'hanya' ~74% (2011), lalu ~83(2012), dan di anggap telah solved di 2015 dengan akurasi ~96% (Deep Convolutional Neural Network - convnets).\n",
    "* Sejak itu convnets menjadi model dasar computer vision.\n",
    "* Di Kaggle (sekitar 2016) ada trend untuk data terstruktur biasanya diselesaikan dengan Gradient Boosting (e.g. XGBoost) dan data tidak terstruktur dengan Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/dataScience_models.gif\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "<img alt=\"\" src=\"images/6_DT.png\" style=\"height:336px; width:904px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/6_DT_meme.png\" style=\"height:342px; width:460px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Explanation of a Decision Tree\n",
    "\n",
    "* http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
    "* http://www.r2d3.us/visual-intro-to-machine-learning-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More resources:\n",
    "\n",
    "* http://www.saedsayad.com/decision_tree.htm\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Asumsi (induktif bias) dari&nbsp; Decision tree</h3>\n",
    "<img alt=\"\" src=\"images/6_asumsi_DT.JPG\" style=\"height:300px; width:300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lebih Tepatnya\n",
    "<p><img alt=\"\" src=\"images/Dec_Tree_Asumsi_Depth.png\" style=\"width: 650px; height: 122px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teori Decision Tree : Information theory\n",
    "<img alt=\"\" src=\"images/dec_Tree_Theory.png\" style=\"width: 600px; height: 337px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/Entropy.png\" style=\"width: 650px; height: 290px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/Information_Gain.png\" style=\"width: 650px; height: 199px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/Contoh_Entropy.png\" style=\"width: 469px; height: 339px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/Contoh_Gain.png\" style=\"width: 650px; height: 456px;\" /></p>\n",
    "* Contoh Lain: http://www.saedsayad.com/decision_tree.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative to Information Gain : Gini Index (CART)\n",
    "https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belum (tidak) Dibahas\n",
    "* Impurity Functions\n",
    "* Prunning\n",
    "* Numeric variables\n",
    "* Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u><strong>When to use:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Target : Binomial/nominal.</li>\n",
    "\t<li>Predictors (input): binomial, nominal, and-or interval (ratio).</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Advantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Fast and embarrassingly parallel.</li>\n",
    "\t<li>Tanpa iterasi, cocok untuk&nbsp;Big Data technology (e.g. Hadoop)[map-reduce friendly]</li>\n",
    "\t<li>Interpretability</li>\n",
    "\t<li>Robust terhadap outliers &amp; missing values</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Disadvantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Non probabilistic (ad hoc heuristic) +/-</li>\n",
    "\t<li>Target dengan banyak kelas</li>\n",
    "\t<li>Sensitive (instability)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFile CSV\n",
    "try:\n",
    "    df = pd.read_csv('data/iris.csv') # run locally\n",
    "except:\n",
    "    !wget https://raw.githubusercontent.com/taufikedys/tau-data/master/data/iris.csv # \"Google Colab\"\n",
    "    df = pd.read_csv('iris.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SPECIES'] = df['SPECIES'].astype('category')\n",
    "print(df.groupby('SPECIES').size())\n",
    "df.describe(include='all') # try without the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Data\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']]\n",
    "Y = df['SPECIES']\n",
    "seed = 9\n",
    "validation_size = 0.3\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and Evaluate\n",
    "dt_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed) # Default Gini\n",
    "dt = dt_model.fit(X_train, Y_train)\n",
    "dt_prediction = dt.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, dt_prediction))\n",
    "print(confusion_matrix(Y_test, dt_prediction))\n",
    "print(classification_report(Y_test, dt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May not work in Google Colab, use Anaconda\n",
    "dot_data = tree.export_graphviz(dt, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\") \n",
    "var_names = ['SEPALLEN','SEPALWID', 'PETALLEN','PETALWID']\n",
    "categories = ['Setosa', 'VersiColor', 'Virginica']\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names = var_names,  \n",
    "                         class_names=categories,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph \n",
    "# Interpretation is much easier from the graph\n",
    "# Installing GraphViz : https://stackoverflow.com/questions/49471867/installing-graphviz-for-use-with-python-3-on-windows-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varible importance\n",
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "var = list(X_train.columns)\n",
    "viz = dtreeviz(dt,\n",
    "              X_train,\n",
    "              Y_train,\n",
    "              target_name='SPECIES',\n",
    "              feature_names=var,\n",
    "              class_names=['Setosa', 'VersiColor', 'Virginica']\n",
    "              )  \n",
    "display(HTML(viz.svg()))\n",
    "#viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/5_RandomForest.png\" style=\"width: 592px; height: 444px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curse of Dimensionality\n",
    "\n",
    "<p><img alt=\"\" src=\"images/chd_1.PNG\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari coba perbaiki dengan Random Forest\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "rf_prediction = rf.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, rf_prediction))\n",
    "print(confusion_matrix(Y_test, rf_prediction))\n",
    "print(classification_report(Y_test, rf_prediction))\n",
    "# Ensemble less effective on strong classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varible importance\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "<img alt=\"\" src=\"images/naive_bayes.png\" style=\"width: 400px ; height: 220px\" />\n",
    "\n",
    "* P(x) konstan, sehingga bisa diabaikan.\n",
    "* Asumsi terkuatnya adalah independensi antar variabel prediktor (sehingga dikatakan &quot;Naive&quot;)\n",
    "* Klasifikasi dilakukan dengan menghitung probabilitas untuk setiap kategori ketika diberikan data x = (x1,x2,...,xm)\n",
    "* Untuk data yang besar bisa menggunakan out-of-core approach (partial fit):<br />\n",
    "\thttp://scikit-learn.org/stable/modules/scaling_strategies.html#scaling-strategies\n",
    "* Variasi NBC adalah bagaimana P(c|x) dihitung, misal dengan distribusi Gaussian (Normal) - sering disebut sebagai Gaussian Naive Bayes (GNB):\n",
    "\n",
    "<img alt=\"\" src=\"images/Gaussian.png\" style=\"width: 303px ; height: 50px\" />\n",
    "\n",
    "* very good explanation of NBC: \n",
    "* https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/ \n",
    "* https://www.saedsayad.com/naive_bayesian.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes in Social Media Analytics\n",
    "\n",
    "* Sentiment Analysis\n",
    "* Topic Modelling\n",
    "\n",
    "<p><img alt=\"\" src=\"images/SNA_Graph_Types.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><em><strong>Pros:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Cepat dan mudah di implementasikan</li>\n",
    "\t<li>Cocok untuk permasalahan multiclass</li>\n",
    "\t<li>Jika asumsi terpenuhi (independent) biasanya performanya cukup baik dan membutuhkan data (training) yang lebih sedikit.</li>\n",
    "\t<li>Biasanya baik digunakan untuk prediktor kategorik, untuk numerik NBC mengasumsikan distribusi normal (terkadang tidak terpenuhi)&nbsp;</li>\n",
    "</ul>\n",
    "\n",
    "<p><em><strong>Cons:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Jika di test data memuat kategori yang tidak ada di training data ( ==&gt; probabilitas = 0). Sering disebut sebagai masalah&nbsp; &ldquo;Zero Frequency&rdquo;.&nbsp;</li>\n",
    "\t<li>Asumsi yang sangat kuat (independen antar prediktor).</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nbc = gnb.fit(X_train, Y_train)\n",
    "nbc_prediction = nbc.predict(X_test)\n",
    "\n",
    "print('Akurasi = ', accuracy_score(Y_test, nbc_prediction))\n",
    "print(confusion_matrix(Y_test, nbc_prediction))\n",
    "print(classification_report(Y_test, nbc_prediction))\n",
    "# Hati-hati Sparse ==> Dense bisa memenuhi memory untuk data relatif cukup besar\n",
    "# Akurasi cukup baik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Metrics in Python</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/6_Evaluasi_ML.JPG\" style=\"height:400px; width:515px\" /></p>\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "gnb = GaussianNB()\n",
    "mulai = time.time()\n",
    "scores_svm = cross_val_score(gnb, X, Y, cv=10,scoring='accuracy') # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy Naive Bayes Classifier: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_svm.mean(), scores_svm.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparisons using Cross Validation\n",
    "Models = [('Naive Bayes',gnb), ('Random Forest',rf), ('Decision Tree',dt_model)]\n",
    "Scores = {}\n",
    "for model_name, model in Models:\n",
    "    Scores[model_name] = cross_val_score(model, X, Y, cv=10,scoring='accuracy')\n",
    "\n",
    "dt = pd.DataFrame.from_dict(Scores)\n",
    "ax = sns.boxplot(data=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>End of Module</h1>\n",
    "<hr />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
